{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0791259-8ae7-4a7f-9380-4a08562c712c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from CAE import ConvAutoencoder\n",
    "from FF_Autoencoder import Autoencoder\n",
    "import torch \n",
    "from Dataset_Loader import ImageDataset\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image,ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b616b17-cc87-4f31-a5f3-267a98d11cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 50\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "SHUFFLE = True\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd23a06c-f4dd-49d4-8610-a93b92ade876",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = \"Dataset/train/\"\n",
    "VAL_PATH = \"Dataset/val1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c4af16f-b1f7-4700-9a13-c8bd82143a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_dataset = ImageDataset(path=TRAIN_PATH,img_size=IMG_SIZE,batch_size=BATCH_SIZE,shuffle=SHUFFLE)\n",
    "val_image_dataset =  ImageDataset(path=VAL_PATH,img_size=IMG_SIZE,batch_size=BATCH_SIZE,shuffle=SHUFFLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d9a2c26-28c6-44a3-9d1d-dc76c77e9406",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = train_image_dataset.get_dataloader()\n",
    "val_loader = val_image_dataset.get_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5339685b-7d77-401f-8fe3-aa9f129476bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Safe': 0, 'notSafe': 1}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image_dataset.get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d22cac6-9637-474e-916c-212d86951e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_autoencoder(model, data_loader, epochs=EPOCHS, learning_rate=LEARNING_RATE):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for data in data_loader:\n",
    "            inputs = data[0]  # Assuming data is a tuple (image, label)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, inputs)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bf4f18-f97f-42c1-abdb-14e262fb2fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8250a153-ad6a-4fba-83a9-253b190262db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
